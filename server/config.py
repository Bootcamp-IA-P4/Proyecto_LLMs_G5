
# /server/config.py

# Configuraci√≥n del modelo de lenguaje a utilizar.
# Cambia este valor para experimentar con otros modelos de Ollama (ej. "llama3", 
# "gemma:2b")
#LLM_MODEL = "tinyllama:latest"
#LLM_MODEL = "mistral:7b-instruct-v0.2-q4_0"
LLM_MODEL = "gemma:2b"
